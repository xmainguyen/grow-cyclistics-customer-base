{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41766cb",
   "metadata": {},
   "source": [
    "#  Causal Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada4c58d",
   "metadata": {},
   "source": [
    "Of course. Here is a README.md file drafted from your notes.\n",
    "\n",
    "-----\n",
    "\n",
    "# The Causal Effect of Warm Temperature on Bike-Share Trip Duration\n",
    "\n",
    "This repository contains the analysis for a study investigating the causal effect of warm weather on the duration of bike-share trips using data from New York City's Citi Bike program.\n",
    "\n",
    "## Research Question & Hypothesis\n",
    "\n",
    "This study investigates the causal effect of warm temperatures on bike-share trip duration.\n",
    "\n",
    "**Hypothesis**: Warmer temperatures causally increase the trip duration of casual customers (leisure riders/tourists) for bike-share services, while having a less significant effect on subscribers (commuters).\n",
    "\n",
    "-----\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Research Design\n",
    "\n",
    "This research employs a **fixed-effects difference-in-differences (DiD)** model to isolate the causal impact of temperature on riding behavior.\n",
    "\n",
    "  * **Treatment Group**: Casual customers, who are more likely to use bike-share services for leisure on warmer days.\n",
    "  * **Control Group**: Subscribers (commuters), who are assumed to have more rigid commuting patterns regardless of temperature.\n",
    "  * **Treatment Variable (X)**: `warm_day`, a binary indicator for days where the average temperature is above 65¬∞F.\n",
    "  * **Outcome Variable (Y)**: `avg_trip_minutes`, the average daily trip duration in minutes for each user type.\n",
    "\n",
    "### Regression Model\n",
    "\n",
    "The core of the analysis is the following regression model, where the coefficient `Œ¥` on the interaction term represents the DiD estimator:\n",
    "\n",
    "```\n",
    "AvgTripMinutes = Œ≤‚ÇÄ + Œ≤‚ÇÅ(warm_day) + Œ≤‚ÇÇ(is_customer) + Œ¥(warm_day * is_customer) + C(holiday) + C(day_of_week) + C(neighborhood) + C(wind_speed) + C(precipitation) + Œµ\n",
    "```\n",
    "\n",
    "### Causal Diagram (DAG)\n",
    "\n",
    "The Directed Acyclic Graph (DAG) below illustrates the assumed causal relationships. Temperature exogenously affects Trip Duration, with User Type modifying this relationship. Day of the Week is a potential confounder.\n",
    "\n",
    "-----\n",
    "\n",
    "## Data\n",
    "\n",
    "### Data Sources and Variables\n",
    "\n",
    "This study uses daily-level aggregated data from two public sources for the year 2018:\n",
    "\n",
    "1.  **NYC Citi Bike Trip Data**\n",
    "2.  **NOAA Global Surface Summary of the Day (GSOD)**\n",
    "\n",
    "**Key Variables:**\n",
    "\n",
    "  * **Outcome (`avg_trip_minutes`)**: The average daily trip duration for a given user type.\n",
    "  * **Treatment (`warm_day`)**: A binary variable indicating if the mean temperature was above 65¬∞F.\n",
    "  * **Controls**: `precipitation`, `wind_speed`, `holiday`, `day_of_week`.\n",
    "  * **Fixed Effects**: The model includes fixed effects for `day_of_week` and `neighborhood` to account for unobserved, time-invariant characteristics.\n",
    "\n",
    "### Pre-Treatment Balance\n",
    "\n",
    "A balance test revealed pre-treatment differences between the control and treatment groups. This suggests a violation of the parallel trends assumption, making the inclusion of control variables essential for isolating a precise causal estimate.\n",
    "\n",
    "-----\n",
    "\n",
    "## Validity\n",
    "\n",
    "### Internal Validity\n",
    "\n",
    "The primary threat to internal validity is **omitted variable bias** from factors correlated with both temperature and riding behavior (e.g., precipitation, wind speed, local events).\n",
    "\n",
    "  * **Mitigation Strategy**: This threat is addressed by including these factors as control variables in the regression and incorporating fixed effects for `neighborhood`, `day_of_week`, and `holiday`. Since temperature is an exogenous variable that individuals cannot influence, self-selection bias is not a primary concern.\n",
    "\n",
    "### External Validity\n",
    "\n",
    "The findings of this study may be specific to **New York City**. The results might not generalize to other cities with different climates, topographies, demographics, or bike-share user compositions (e.g., a lower tourist-to-commuter ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "268ce87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da220a18",
   "metadata": {},
   "source": [
    "## Questions for OH \n",
    "\n",
    "1. Do we usually do data cleaning for causal inference? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a48b4",
   "metadata": {},
   "source": [
    "## Test Regression Discontinuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69543c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume 'df' is your DataFrame with the columns:\n",
    "# 'avg_trip_minutes' and 'day_mean_temperature'\n",
    "\n",
    "# 1. Choose a plausible cutoff temperature\n",
    "cutoff = 30\n",
    "\n",
    "# 2. Create a new column to identify data above or below the cutoff\n",
    "df['is_below_cutoff'] = (df['day_mean_temperature'] <= cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7ac531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume 'df' is your DataFrame with the columns:\n",
    "# 'avg_trip_minutes' and 'day_mean_temperature'\n",
    "\n",
    "# 1. Change the cutoff temperature to 30¬∞F\n",
    "cutoff = 30\n",
    "\n",
    "# 2. Create the new column based on the 30¬∞F cutoff\n",
    "df['is_above_cutoff'] = (df['day_mean_temperature'] >= cutoff)\n",
    "\n",
    "# Create the regression discontinuity plot\n",
    "sns.lmplot(\n",
    "    data=df,\n",
    "    x='day_mean_temperature',\n",
    "    y='avg_trip_minutes',\n",
    "    hue='is_above_cutoff',\n",
    "    height=7,\n",
    "    aspect=1.5\n",
    ")\n",
    "\n",
    "# Add a vertical line at the new cutoff point\n",
    "plt.axvline(x=cutoff, color='red', linestyle='--')\n",
    "\n",
    "# Update the title and labels for clarity\n",
    "plt.title('Regression Discontinuity at 30¬∞F')\n",
    "plt.xlabel('Day Mean Temperature (¬∞F)')\n",
    "plt.ylabel('Average Trip Minutes')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdc1bc4",
   "metadata": {},
   "source": [
    "## 1.a.\n",
    "\n",
    "**Answer**\n",
    "\n",
    "From the balance tests, it confirms that pre-treatment differences exist. \"children\", \"nonwhite\", \"finc\", \"earn\", \"age\", \"ed\", \"work\" are all statistically significant with the treatment. \n",
    "\n",
    "This violates the parallel trends assumption needed for DiD, and since treatment is endogenous to those factors. Not controlling for them will be a thread to a precise causal estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c80fecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usertype</th>\n",
       "      <th>zip_code_start</th>\n",
       "      <th>borough_start</th>\n",
       "      <th>neighborhood_start</th>\n",
       "      <th>zip_code_end</th>\n",
       "      <th>borough_end</th>\n",
       "      <th>neighborhood_end</th>\n",
       "      <th>start_day</th>\n",
       "      <th>stop_day</th>\n",
       "      <th>day_mean_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>trip_minutes</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>unique_bikes_used</th>\n",
       "      <th>total_trip_minutes</th>\n",
       "      <th>avg_trip_minutes</th>\n",
       "      <th>median_trip_minutes</th>\n",
       "      <th>min_trip_minutes</th>\n",
       "      <th>max_trip_minutes</th>\n",
       "      <th>warm</th>\n",
       "      <th>treated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subscriber</td>\n",
       "      <td>10065</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Upper East Side</td>\n",
       "      <td>10168</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Gramercy Park and Murray Hill</td>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>37.7</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>44.950000</td>\n",
       "      <td>11.237500</td>\n",
       "      <td>11.066667</td>\n",
       "      <td>8.383333</td>\n",
       "      <td>13.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subscriber</td>\n",
       "      <td>10024</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Upper West Side</td>\n",
       "      <td>10022</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Gramercy Park and Murray Hill</td>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>9.7</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37.266667</td>\n",
       "      <td>18.633333</td>\n",
       "      <td>15.016667</td>\n",
       "      <td>15.016667</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subscriber</td>\n",
       "      <td>10023</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Upper West Side</td>\n",
       "      <td>10035</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>43.6</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>63.316667</td>\n",
       "      <td>21.105556</td>\n",
       "      <td>21.233333</td>\n",
       "      <td>20.766667</td>\n",
       "      <td>21.316667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subscriber</td>\n",
       "      <td>10001</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Chelsea and Clinton</td>\n",
       "      <td>10199</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Chelsea and Clinton</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>24.9</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>67.883333</td>\n",
       "      <td>5.656944</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>7.633333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subscriber</td>\n",
       "      <td>11103</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Northwest Queens</td>\n",
       "      <td>11101</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Northwest Queens</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>48.7</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>103.066667</td>\n",
       "      <td>17.177778</td>\n",
       "      <td>17.116667</td>\n",
       "      <td>15.366667</td>\n",
       "      <td>19.283333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     usertype  zip_code_start borough_start   neighborhood_start  \\\n",
       "0  Subscriber           10065     Manhattan      Upper East Side   \n",
       "1  Subscriber           10024     Manhattan      Upper West Side   \n",
       "2  Subscriber           10023     Manhattan      Upper West Side   \n",
       "3  Subscriber           10001     Manhattan  Chelsea and Clinton   \n",
       "4  Subscriber           11103        Queens     Northwest Queens   \n",
       "\n",
       "   zip_code_end borough_end               neighborhood_end   start_day  \\\n",
       "0         10168   Manhattan  Gramercy Park and Murray Hill  2023-03-22   \n",
       "1         10022   Manhattan  Gramercy Park and Murray Hill  2023-01-07   \n",
       "2         10035   Manhattan                    East Harlem  2023-01-13   \n",
       "3         10199   Manhattan            Chelsea and Clinton  2023-01-31   \n",
       "4         11101      Queens               Northwest Queens  2023-02-22   \n",
       "\n",
       "     stop_day  day_mean_temperature  ...  trip_minutes  trip_count  \\\n",
       "0  2023-03-22                  37.7  ...            10           4   \n",
       "1  2023-01-07                   9.7  ...            20           2   \n",
       "2  2023-01-13                  43.6  ...            20           3   \n",
       "3  2023-01-31                  24.9  ...            10          12   \n",
       "4  2023-02-22                  48.7  ...            20           6   \n",
       "\n",
       "   unique_bikes_used  total_trip_minutes  avg_trip_minutes  \\\n",
       "0                  4           44.950000         11.237500   \n",
       "1                  2           37.266667         18.633333   \n",
       "2                  3           63.316667         21.105556   \n",
       "3                 12           67.883333          5.656944   \n",
       "4                  6          103.066667         17.177778   \n",
       "\n",
       "   median_trip_minutes  min_trip_minutes  max_trip_minutes  warm  treated  \n",
       "0            11.066667          8.383333         13.933333     0        0  \n",
       "1            15.016667         15.016667         22.250000     0        0  \n",
       "2            21.233333         20.766667         21.316667     0        0  \n",
       "3             5.266667          4.600000          7.633333     0        0  \n",
       "4            17.116667         15.366667         19.283333     0        0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data \n",
    "df = pd.read_csv('../data/trips.csv')\n",
    "\n",
    "# Define POST as 1994 and after\n",
    "df['warm'] = (df['day_mean_temperature'] >= 60).astype(int)\n",
    "\n",
    "# Define TREATED group as respondent who has 1 or more children\n",
    "df['treated'] = (df['usertype'] == 'Customer').astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d157369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create holiday dummy variable based on US federal holidays 1 if not 0 \n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "cal = USFederalHolidayCalendar()\n",
    "holidays = cal.holidays(start='2018-01-01', end='2018-12-31')\n",
    "df['start_day'] = pd.to_datetime(df['start_day'])\n",
    "df['holiday'] = df['start_day'].dt.normalize().isin(holidays).astype(int)\n",
    "\n",
    "# create day of week variable as numeric and string\n",
    "df['day_of_week_num'] = df['start_day'].dt.dayofweek\n",
    "df['day_of_week'] = df['start_day'].dt.day_name()\n",
    "\n",
    "  # create holiday dummy variable based on US federal holidays 1 if not 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bc9fd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['usertype', 'zip_code_start', 'borough_start', 'neighborhood_start',\n",
       "       'zip_code_end', 'borough_end', 'neighborhood_end', 'start_day',\n",
       "       'stop_day', 'day_mean_temperature', 'day_mean_wind_speed',\n",
       "       'day_total_precipitation', 'trip_minutes', 'trip_count',\n",
       "       'unique_bikes_used', 'total_trip_minutes', 'avg_trip_minutes',\n",
       "       'median_trip_minutes', 'min_trip_minutes', 'max_trip_minutes', 'warm',\n",
       "       'treated', 'holiday', 'day_of_week_num', 'day_of_week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7434204f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>day_of_week_num</th>\n",
       "      <th>zip_code_start</th>\n",
       "      <th>day_mean_wind_speed</th>\n",
       "      <th>day_total_precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>730088.0</td>\n",
       "      <td>730088.000000</td>\n",
       "      <td>730088.000000</td>\n",
       "      <td>730088.000000</td>\n",
       "      <td>730088.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.935758</td>\n",
       "      <td>10276.190185</td>\n",
       "      <td>4.589558</td>\n",
       "      <td>0.132375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.008973</td>\n",
       "      <td>468.591262</td>\n",
       "      <td>2.101441</td>\n",
       "      <td>0.285154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10001.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10012.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10024.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10168.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11238.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>1.680000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        holiday  day_of_week_num  zip_code_start  day_mean_wind_speed  \\\n",
       "count  730088.0    730088.000000   730088.000000        730088.000000   \n",
       "mean        0.0         2.935758    10276.190185             4.589558   \n",
       "std         0.0         2.008973      468.591262             2.101441   \n",
       "min         0.0         0.000000    10001.000000             1.000000   \n",
       "25%         0.0         1.000000    10012.000000             2.800000   \n",
       "50%         0.0         3.000000    10024.000000             4.500000   \n",
       "75%         0.0         5.000000    10168.000000             5.800000   \n",
       "max         0.0         6.000000    11238.000000            11.500000   \n",
       "\n",
       "       day_total_precipitation  \n",
       "count            730088.000000  \n",
       "mean                  0.132375  \n",
       "std                   0.285154  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   0.000000  \n",
       "75%                   0.110000  \n",
       "max                   1.680000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0b68d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/opt/anaconda3/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1872: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return self.mse_model/self.mse_resid\n",
      "/opt/anaconda3/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:958: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/opt/anaconda3/lib/python3.12/site-packages/statsmodels/stats/stattools.py:50: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dw = np.sum(diff_resids**2, axis=axis) / np.sum(resids**2, axis=axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balance test for holiday:\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept           0          0        nan        nan           0           0\n",
      "treated             0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "\n",
      "Balance test for day_of_week_num:\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.8589      0.003   1071.964      0.000       2.854       2.864\n",
      "treated        0.3393      0.006     60.566      0.000       0.328       0.350\n",
      "==============================================================================\n",
      "\n",
      "Balance test for zip_code_start:\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   1.028e+04      0.623   1.65e+04      0.000    1.03e+04    1.03e+04\n",
      "treated      -34.0984      1.309    -26.044      0.000     -36.665     -31.532\n",
      "==============================================================================\n",
      "\n",
      "Balance test for day_mean_wind_speed:\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      4.6964      0.003   1686.738      0.000       4.691       4.702\n",
      "treated       -0.4715      0.006    -80.618      0.000      -0.483      -0.460\n",
      "==============================================================================\n",
      "\n",
      "Balance test for day_total_precipitation:\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1384      0.000    364.931      0.000       0.138       0.139\n",
      "treated       -0.0265      0.001    -33.288      0.000      -0.028      -0.025\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run a balance test for each variable in this\n",
    "# 1992 subsample, e.g., by regressing each variable on the indicator for treated. \n",
    "# Discuss what your results imply from an identification perspective\n",
    "\n",
    "cols = ['holiday', 'day_of_week_num', 'zip_code_start', 'day_mean_wind_speed', 'day_total_precipitation']\n",
    "\n",
    "# Balance tests\n",
    "balance_results = {}\n",
    "for var in cols:\n",
    "    model = smf.ols(f\"{var} ~ treated\", data=df).fit()\n",
    "    balance_results[var] = model.summary().tables[1]  # Coefficients table\n",
    "\n",
    "# Print balance results\n",
    "for var, result in balance_results.items():\n",
    "    print(f\"\\nBalance test for {var}:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aef508",
   "metadata": {},
   "source": [
    "## 1.b. \n",
    "\n",
    "**Answer**\n",
    "\n",
    "Earlier, we detected pre-treatment differences between the two groups. Specifically, single-mothers are 0.1326 less likely to work compared to non-mothers. However, from the graph, we can identify a fairly parallel trends of employment between the two groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e7b5217",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the average percent of observations working (i.e., work ==1) \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# by year and treatment status (mothers vs. non).\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m avg_work \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreated\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      5\u001b[0m avg_work[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m avg_work[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreated\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNon-mothers\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m                                                \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSingle-mothers\u001b[39m\u001b[38;5;124m'\u001b[39m}) \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Plot average work separately against year for treated (red), and\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# untreated (blue). Do you think the parallel trends assum\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   9184\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9185\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[1;32m   9186\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   9187\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   9188\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[1;32m   9189\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   9190\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[1;32m   9191\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[1;32m   9192\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[1;32m   9193\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[1;32m   1330\u001b[0m         obj,\n\u001b[1;32m   1331\u001b[0m         keys,\n\u001b[1;32m   1332\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   1333\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   1334\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   1335\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[1;32m   1336\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[1;32m   1337\u001b[0m     )\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'year'"
     ]
    }
   ],
   "source": [
    "# Calculate the average percent of observations working (i.e., work ==1) \n",
    "# by year and treatment status (mothers vs. non).\n",
    "\n",
    "avg_work = df.groupby(['year', 'treated'])['work'].mean().reset_index()\n",
    "avg_work['treated'] = avg_work['treated'].map({0: 'Non-mothers', \n",
    "                                               1: 'Single-mothers'}) \n",
    "\n",
    "\n",
    "# Plot average work separately against year for treated (red), and\n",
    "# untreated (blue). Do you think the parallel trends assum\n",
    "sns.lineplot(data=avg_work, x='year', y='work', hue='treated', palette=['blue', 'red'])\n",
    "plt.title('Average Work by Year and Treatment Status')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Work')\n",
    "plt.legend(title='Group')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ef370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year         treated      work\n",
      "0   1991     Non-mothers  0.583032\n",
      "1   1991  Single-mothers  0.460053\n",
      "2   1992     Non-mothers  0.571566\n",
      "3   1992  Single-mothers  0.438920\n",
      "4   1993     Non-mothers  0.571144\n",
      "5   1993  Single-mothers  0.437547\n",
      "6   1994     Non-mothers  0.590909\n",
      "7   1994  Single-mothers  0.464032\n",
      "8   1995     Non-mothers  0.574236\n",
      "9   1995  Single-mothers  0.508127\n",
      "10  1996     Non-mothers  0.552480\n",
      "11  1996  Single-mothers  0.502636\n"
     ]
    }
   ],
   "source": [
    "print(avg_work)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b901d2e4",
   "metadata": {},
   "source": [
    "## 1.c. \n",
    "\n",
    "Use a linear probability model to calculate the DID estimate of the effect of the EITC expansion on whether a respondent was working (i.e., work ==1) for the whole sample by estimating the model \\\n",
    "\\\n",
    "ùë§ùëúùëüùëò! = ùõº + ùõΩ*ùëùùëúùë†ùë° + ùõΩ*ùë°ùëüùëíùëéùë°ùëíd + ùõΩ*ùëùùëúùë†ùë°*ùë°ùëüùëíùëéùë°ùëíd + ùúÄ \\\n",
    "\\\n",
    "first as is, \n",
    "and then with fixed effects in state and year. Interpret your results for both regressions, and comment on any differences.\n",
    "\n",
    "**Answer**\n",
    "\n",
    "After adding the state and year fixed-effects, the coefficients of treated and post*treated change slightly. This means that the state-level patterns and seasonal shocks on employment did bias the estimates before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a5e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       avg_trip_minutes   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     175.2\n",
      "Date:                Mon, 29 Sep 2025   Prob (F-statistic):          1.44e-113\n",
      "Time:                        23:22:54   Log-Likelihood:            -6.2179e+06\n",
      "No. Observations:              730088   AIC:                         1.244e+07\n",
      "Df Residuals:                  730084   BIC:                         1.244e+07\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept       30.1350      1.878     16.051      0.000      26.455      33.815\n",
      "warm             6.3358      3.644      1.739      0.082      -0.807      13.479\n",
      "treated         58.1428      4.329     13.432      0.000      49.659      66.627\n",
      "warm:treated    34.8608      7.040      4.952      0.000      21.062      48.660\n",
      "==============================================================================\n",
      "Omnibus:                  3187763.394   Durbin-Watson:                   2.001\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   17854667382239.758\n",
      "Skew:                         136.034   Prob(JB):                         0.00\n",
      "Kurtosis:                   24228.152   Cond. No.                         6.11\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# DiD estimate of the effect of the EITC expansion on whether a respondent was working\n",
    "# (i.e., work ==1) for the whole sample\n",
    "model = smf.ols(\"avg_trip_minutes ~ warm + treated + warm:treated\", data=df).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea503c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       avg_trip_minutes   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     19.43\n",
      "Date:                Mon, 29 Sep 2025   Prob (F-statistic):          1.28e-244\n",
      "Time:                        23:25:55   Log-Likelihood:            -6.2174e+06\n",
      "No. Observations:              730088   AIC:                         1.244e+07\n",
      "Df Residuals:                  730015   BIC:                         1.244e+07\n",
      "Df Model:                          72                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Intercept                      26.3945      8.770      3.010      0.003       9.205      43.583\n",
      "C(zip_code_start)[T.10002]     -1.0393     11.321     -0.092      0.927     -23.228      21.150\n",
      "C(zip_code_start)[T.10003]      2.2466     10.950      0.205      0.837     -19.214      23.708\n",
      "C(zip_code_start)[T.10004]     -7.8969     13.271     -0.595      0.552     -33.907      18.113\n",
      "C(zip_code_start)[T.10005]     -8.9222     14.737     -0.605      0.545     -37.807      19.963\n",
      "C(zip_code_start)[T.10007]      9.1170     12.510      0.729      0.466     -15.402      33.636\n",
      "C(zip_code_start)[T.10009]     -4.9474     11.847     -0.418      0.676     -28.167      18.272\n",
      "C(zip_code_start)[T.10010]     -5.4568     11.865     -0.460      0.646     -28.711      17.798\n",
      "C(zip_code_start)[T.10011]      6.2791     11.075      0.567      0.571     -15.427      27.985\n",
      "C(zip_code_start)[T.10012]     -3.8662     11.718     -0.330      0.741     -26.833      19.101\n",
      "C(zip_code_start)[T.10013]     -2.8287     11.887     -0.238      0.812     -26.127      20.469\n",
      "C(zip_code_start)[T.10014]     -2.4085     11.575     -0.208      0.835     -25.095      20.278\n",
      "C(zip_code_start)[T.10016]     -0.1704     11.533     -0.015      0.988     -22.775      22.434\n",
      "C(zip_code_start)[T.10017]    -11.8441     12.620     -0.938      0.348     -36.580      12.892\n",
      "C(zip_code_start)[T.10018]     18.7471     11.736      1.597      0.110      -4.254      41.748\n",
      "C(zip_code_start)[T.10019]     -4.5594     11.038     -0.413      0.680     -26.193      17.074\n",
      "C(zip_code_start)[T.10021]     -6.9751     13.939     -0.500      0.617     -34.296      20.346\n",
      "C(zip_code_start)[T.10022]     -8.9941     12.101     -0.743      0.457     -32.712      14.724\n",
      "C(zip_code_start)[T.10023]      2.8073     11.014      0.255      0.799     -18.779      24.394\n",
      "C(zip_code_start)[T.10024]     -2.5847     11.825     -0.219      0.827     -25.762      20.592\n",
      "C(zip_code_start)[T.10025]     12.0733     12.521      0.964      0.335     -12.468      36.614\n",
      "C(zip_code_start)[T.10026]     38.3743     16.112      2.382      0.017       6.796      69.953\n",
      "C(zip_code_start)[T.10027]     44.4540     14.802      3.003      0.003      15.443      73.465\n",
      "C(zip_code_start)[T.10028]     -3.9479     13.746     -0.287      0.774     -30.890      22.994\n",
      "C(zip_code_start)[T.10029]      4.2867     13.116      0.327      0.744     -21.420      29.993\n",
      "C(zip_code_start)[T.10035]      2.4111     17.542      0.137      0.891     -31.971      36.793\n",
      "C(zip_code_start)[T.10036]     -6.5040     11.520     -0.565      0.572     -29.083      16.076\n",
      "C(zip_code_start)[T.10037]     61.9982     29.846      2.077      0.038       3.501     120.495\n",
      "C(zip_code_start)[T.10038]     -8.8181     12.904     -0.683      0.494     -34.109      16.472\n",
      "C(zip_code_start)[T.10065]     -3.6418     12.814     -0.284      0.776     -28.756      21.472\n",
      "C(zip_code_start)[T.10069]     -9.6960     20.108     -0.482      0.630     -49.106      29.714\n",
      "C(zip_code_start)[T.10075]     -6.0156     16.476     -0.365      0.715     -38.307      26.276\n",
      "C(zip_code_start)[T.10103]    -13.1255     19.019     -0.690      0.490     -50.402      24.151\n",
      "C(zip_code_start)[T.10110]     -9.7534     18.209     -0.536      0.592     -45.443      25.936\n",
      "C(zip_code_start)[T.10115]     -9.9292     31.307     -0.317      0.751     -71.291      51.432\n",
      "C(zip_code_start)[T.10128]     -0.0481     14.311     -0.003      0.997     -28.098      28.002\n",
      "C(zip_code_start)[T.10167]     -6.7545     16.956     -0.398      0.690     -39.987      26.478\n",
      "C(zip_code_start)[T.10168]     -7.7413     13.669     -0.566      0.571     -34.532      19.050\n",
      "C(zip_code_start)[T.10173]    -21.2895     31.331     -0.680      0.497     -82.697      40.118\n",
      "C(zip_code_start)[T.10199]      1.1400     17.353      0.066      0.948     -32.871      35.151\n",
      "C(zip_code_start)[T.10278]    -14.2050     20.451     -0.695      0.487     -54.288      25.878\n",
      "C(zip_code_start)[T.10280]    -10.8813     13.874     -0.784      0.433     -38.073      16.311\n",
      "C(zip_code_start)[T.10282]     -9.8627     14.036     -0.703      0.482     -37.372      17.647\n",
      "C(zip_code_start)[T.11101]      3.2576     13.791      0.236      0.813     -23.773      30.288\n",
      "C(zip_code_start)[T.11102]      6.4287     21.768      0.295      0.768     -36.237      49.094\n",
      "C(zip_code_start)[T.11103]     -6.1887     22.768     -0.272      0.786     -50.813      38.435\n",
      "C(zip_code_start)[T.11105]    -10.8213     26.379     -0.410      0.682     -62.523      40.880\n",
      "C(zip_code_start)[T.11106]     -4.5271     18.744     -0.242      0.809     -41.265      32.211\n",
      "C(zip_code_start)[T.11109]      1.9436     37.853      0.051      0.959     -72.246      76.133\n",
      "C(zip_code_start)[T.11201]     44.9626     11.689      3.846      0.000      22.052      67.873\n",
      "C(zip_code_start)[T.11205]     47.8955     14.033      3.413      0.001      20.391      75.400\n",
      "C(zip_code_start)[T.11206]     91.4381     15.564      5.875      0.000      60.933     121.943\n",
      "C(zip_code_start)[T.11211]     73.8128     13.145      5.615      0.000      48.049      99.576\n",
      "C(zip_code_start)[T.11215]      9.9372     15.115      0.657      0.511     -19.687      39.561\n",
      "C(zip_code_start)[T.11216]    176.1333     15.767     11.171      0.000     145.231     207.035\n",
      "C(zip_code_start)[T.11217]     46.7006     14.126      3.306      0.001      19.015      74.386\n",
      "C(zip_code_start)[T.11220]     -3.5146    166.190     -0.021      0.983    -329.242     322.213\n",
      "C(zip_code_start)[T.11221]     28.1454     20.587      1.367      0.172     -12.204      68.494\n",
      "C(zip_code_start)[T.11222]     21.2211     14.531      1.460      0.144      -7.259      49.702\n",
      "C(zip_code_start)[T.11225]    151.9906     21.462      7.082      0.000     109.926     194.055\n",
      "C(zip_code_start)[T.11231]     15.3922     15.261      1.009      0.313     -14.518      45.303\n",
      "C(zip_code_start)[T.11232]      4.3327     29.275      0.148      0.882     -53.045      61.710\n",
      "C(zip_code_start)[T.11233]    603.3879     30.077     20.062      0.000     544.439     662.337\n",
      "C(zip_code_start)[T.11238]     78.6820     13.342      5.897      0.000      52.532     104.832\n",
      "C(day_of_week)[T.Monday]      -14.4057      5.254     -2.742      0.006     -24.704      -4.107\n",
      "C(day_of_week)[T.Saturday]     -7.0675      5.475     -1.291      0.197     -17.798       3.663\n",
      "C(day_of_week)[T.Sunday]       -4.6861      5.280     -0.887      0.375     -15.035       5.663\n",
      "C(day_of_week)[T.Thursday]     -7.7647      5.359     -1.449      0.147     -18.269       2.739\n",
      "C(day_of_week)[T.Tuesday]      -6.5536      5.323     -1.231      0.218     -16.986       3.879\n",
      "C(day_of_week)[T.Wednesday]    -6.9076      5.248     -1.316      0.188     -17.194       3.379\n",
      "warm                            5.7501      3.687      1.559      0.119      -1.477      12.977\n",
      "treated                        57.9542      4.395     13.186      0.000      49.340      66.569\n",
      "warm:treated                   35.3370      7.047      5.014      0.000      21.525      49.149\n",
      "==============================================================================\n",
      "Omnibus:                  3187299.267   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   17844926171827.867\n",
      "Skew:                         135.967   Prob(JB):                         0.00\n",
      "Kurtosis:                   24221.543   Cond. No.                         136.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# DiD estimate with fixed effects in state and year\n",
    "model_fe = smf.ols(\"avg_trip_minutes ~ warm + treated + warm:treated + C(zip_code_start) + C(day_of_week)\", data=df).fit()\n",
    "print(model_fe.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dedd889",
   "metadata": {},
   "source": [
    "## 1.d. \n",
    "\n",
    "Why might you be concerned about inference, i.e., the calculation of your standard errors, from\n",
    "these results? What could you do to alleviate these concerns? Implement at least one of the\n",
    "techniques from Bertrand Duflo and Mullainathan (2004) and report on the change?\n",
    "\n",
    "**Answer**\n",
    "\n",
    "Since we know, a state-level or year-level patterns and shocks can affect all the observations in that group. The earlier naive regression treated the each observation as independence. This made the standard errors smaller and underestimated the p-value (false significance). \n",
    "\n",
    "So one way to alleviate this concern is to apply clusered standard errors to account for these effects in state and year-level. \n",
    "\n",
    "After including the clusted SE, the estimate does not change, but the clustered SE gets larger (0.012 to 0.017) after considering the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7da00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       avg_trip_minutes   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     17.71\n",
      "Date:                Mon, 29 Sep 2025   Prob (F-statistic):           1.89e-08\n",
      "Time:                        23:27:27   Log-Likelihood:            -6.2179e+06\n",
      "No. Observations:              730088   AIC:                         1.244e+07\n",
      "Df Residuals:                  730084   BIC:                         1.244e+07\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:              cluster                                         \n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept       30.1350      1.227     24.566      0.000      27.731      32.539\n",
      "warm             6.3358      1.219      5.198      0.000       3.947       8.725\n",
      "treated         58.1428     10.722      5.423      0.000      37.129      79.157\n",
      "warm:treated    34.8608     14.512      2.402      0.016       6.418      63.303\n",
      "==============================================================================\n",
      "Omnibus:                  3187763.394   Durbin-Watson:                   2.001\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   17854667382239.758\n",
      "Skew:                         136.034   Prob(JB):                         0.00\n",
      "Kurtosis:                   24228.152   Cond. No.                         6.11\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "# DID regression with clustered standard errors at the state level\n",
    "model = smf.ols(\"avg_trip_minutes ~ warm + treated + warm:treated\", data=df).fit(\n",
    "    cov_type=\"cluster\", cov_kwds={\"groups\": df[\"zip_code_start\"]}\n",
    ")\n",
    "print(model.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
